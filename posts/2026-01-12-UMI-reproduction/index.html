<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>index – Author</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-0b37c64f34216b628666a8dac638b53b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Author</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/vauthor31"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block"></header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="umi-reproduction" class="level1">
<h1>UMI Reproduction</h1>
</section>
<section id="goal" class="level1">
<h1>Goal</h1>
<p>To reproduce UMI (Universal Manipulation Interface), a data collection methodology, integrate to IsaacSim.</p>
<section id="challenges" class="level2">
<h2 class="anchored" data-anchor-id="challenges">Challenges</h2>
<ul>
<li>Official implementation doesn’t support latest GoPro13 devices:
<ul>
<li>GoPro13 latest format causing official IMU extraction failure.<br>
</li>
<li>In-accurate intrinsics, extrinsics, noise parameters causing SLAM failure.<br>
</li>
<li>The business logic is currently hard-coded exclusively for the GoPro9.<br>
</li>
</ul></li>
<li>IsaacSim V5.1.0 integration, to validate the collected data, trained policy, inferencing stacks right in the simulator.
<ul>
<li>Validate the collected data: Replay the extracted trajectories right in the simulator ( where should this section be?)<br>
</li>
</ul></li>
<li>Train a policy model on cutting-task
<ul>
<li>Design a task-specific collection device for such cutting tasks, relies on CORE.</li>
</ul></li>
</ul>
</section>
</section>
<section id="what-worked" class="level1">
<h1>What worked</h1>
<p>Note: The following outlines the successful implementation of the aforementioned challenges.</p>
<section id="gopro13-latest-format-causing-official-imu-extraction-failure" class="level2">
<h2 class="anchored" data-anchor-id="gopro13-latest-format-causing-official-imu-extraction-failure">GoPro13 latest format causing official IMU extraction failure</h2>
<ul>
<li>Integrated latest sensor data extraction library.</li>
</ul>
</section>
<section id="in-accurate-intrinsics-extrinsics-noise-parameters-causing-slam-failure" class="level2">
<h2 class="anchored" data-anchor-id="in-accurate-intrinsics-extrinsics-noise-parameters-causing-slam-failure">In-accurate intrinsics, extrinsics, noise parameters causing SLAM failure</h2>
<ul>
<li>Calibrated GoPro13 to obtains the following values:
<ul>
<li>Camera intrinsics parameters<br>
</li>
<li>IMU noise calibration<br>
</li>
<li>IMU frequency</li>
</ul></li>
</ul>
</section>
<section id="the-business-logic-is-currently-hard-coded-exclusively-for-the-gopro9." class="level2">
<h2 class="anchored" data-anchor-id="the-business-logic-is-currently-hard-coded-exclusively-for-the-gopro9.">The business logic is currently hard-coded exclusively for the GoPro9.</h2>
<ul>
<li>Re-implemented UMI processing pipeline in a separate repository, voilab, contains:
<ul>
<li>The new UMI implementation is designed for extensibility, enabling flexible integration of new processing logic such as alternative SLAM or others.<br>
</li>
<li>Data visualization tools<br>
</li>
<li>URDF viewer</li>
</ul></li>
</ul>
<p>More on the new design of the UMI pipeline. A YAML-based pipeline configuration, each stage corresponding to a service such as SLAM, Aruco detection service, etc. This design enables the ease of extension as discussed above. For example, the current SLAM service is based on the implementation ORB_SLAM3, we could easily swap for other SLAM method such as Realsense T265 built-in Visual SLAM.</p>
</section>
<section id="isaacsim-v5.1.0-integration-to-validate-the-collected-data-trained-policy-inferencing-stacks-right-in-the-simulator." class="level2">
<h2 class="anchored" data-anchor-id="isaacsim-v5.1.0-integration-to-validate-the-collected-data-trained-policy-inferencing-stacks-right-in-the-simulator.">IsaacSim V5.1.0 integration, to validate the collected data, trained policy, inferencing stacks right in the simulator.</h2>
<ul>
<li>Containerized IsaacSim V5.1.0 into the repository allowing ease of installation, development.<br>
</li>
<li>Integrated ROS2, the goal is to streamline the policy deployment on simulation and real-world environments. It comes with a cost, which will be discussed later in the “Technical debt” section.</li>
</ul>
<section id="how-does-ros-help-reduce-the-deployment-and-maintenance-efforts" class="level3">
<h3 class="anchored" data-anchor-id="how-does-ros-help-reduce-the-deployment-and-maintenance-efforts">How does ROS help reduce the deployment and maintenance efforts?</h3>
<p><strong>Claim</strong>: Streamlining the deployment process can help reduce the development and maintenance effort.<br>
Isaac Sim v5.1.0 provides native ROS 2 support, enabling seamless communication with the simulator. This allows the inference stack to be shared between the simulation and real-world deployments.</p>
<ul>
<li>Be able to test and iterate the inference pipeline in the simulation environment, then deploy directly to real hardware.</li>
</ul>
</section>
<section id="isaacsims-action-graph-utilization" class="level3">
<h3 class="anchored" data-anchor-id="isaacsims-action-graph-utilization">IsaacSim’s action graph utilization</h3>
<p>IsaacSim supports ROS2 natively via the “Action Graph” layer. This is a place to define a graph containing nodes that publishes sensor information or subscribes to certain ROS topics and acts upon the received commands. In the example of controlling the robotic arm, certain nodes are needed:</p>
<ul>
<li>A subscriber node: subscribes to a topic of joint positions<br>
</li>
<li>A controller node: controls the robotic arm by joint positions commands</li>
</ul>
<p>Such design could help future robotic arm swapping easily without being bound by any components.</p>
</section>
<section id="real-world-trajectory-replay-inside-isaacsim-simulator" class="level3">
<h3 class="anchored" data-anchor-id="real-world-trajectory-replay-inside-isaacsim-simulator">Real-world trajectory replay inside IsaacSim simulator</h3>
<p>At the start of the human demonstration collection stage of the UMI method, a world-coordinate calibration is needed, which is recording an Aruco tag placed on the surface which is treated as world coordinate in upcoming human demonstration trajectories recording. UMI pipeline would later transform extracted trajectories from ORB_SLAM3 to this tag frame. To replay it, we must transform all waypoints from that Aruco tag frame to the simulation world frame.</p>
<section id="implementation-details" class="level4">
<h4 class="anchored" data-anchor-id="implementation-details">Implementation details:</h4>
<p>All waypoints of each trajectory are end-effector pose, to have the robotic arm in the simulation replayed such waypoints, there are few processing steps to follow:</p>
<ul>
<li>Transform waypoints from original tag-frame to simulation world frame<br>
</li>
<li>Convert waypoints in end-effector pose to joint positions which eventually moves the robotic arm.
<ul>
<li>IsaacSim built-in ArticulationKinematicsSolver was used</li>
</ul></li>
</ul>
</section>
</section>
<section id="version-control-for-simulation-assets." class="level3">
<h3 class="anchored" data-anchor-id="version-control-for-simulation-assets.">Version control for simulation assets.</h3>
<p>Git was employed in order to manage the version of simulation assets enabling the ease of collaboration work across a team.</p>
</section>
</section>
</section>
<section id="what-didnt" class="level1">
<h1>What didn’t</h1>
<p><strong>Note</strong>: This section outlines failures, discussing what could be done better in future works.</p>
<section id="grasping-failure-in-the-simulation-environment" class="level2">
<h2 class="anchored" data-anchor-id="grasping-failure-in-the-simulation-environment">Grasping failure in the simulation environment</h2>
<p>The robotic arm was unable to grasp the objects in the simulation environment while replaying the collected trajectories in the real-world environment. There is an on-going investigation on this issue, the followings were tried but didn’t have effects.</p>
<ul>
<li>Configure the franka-grippers and objects with rigid body and collider<br>
</li>
<li>Replaced the UMI-gripper Franka with the official one but the grasping issue wasn’t resolved</li>
</ul>
</section>
<section id="trajectory-intervention" class="level2">
<h2 class="anchored" data-anchor-id="trajectory-intervention">Trajectory intervention</h2>
<p>There are certain biases in object reconstructions, trajectories extraction from SLAM. These accumulated biases led to inaccurate robotic arm movements. To mitigate this issue, an intervention methodology was employed. The idea was to intercept the original trajectory when certain conditions were met, close to objects, the gripper width was in a certain range, etc. However, this intervention could potentially disrespect the real-world trajectory. Taking the cup-stacking as an example, the human-expert was intended to present certain failures before actually grasping the cup. This intervention method patches those failures with the synthetic, ad-hoc trajectory. Eventually, this type of method just broadens the sim-real gap rather than solving the issue as it was originally designed. We shouldn’t solve the problem at this layer but from the very first principle, detect and eliminate those biases.</p>
</section>
</section>
<section id="adaptations-for-the-physical-ai-course" class="level1">
<h1>Adaptations for the Physical AI course</h1>
<section id="task-specific-scene-loading-and-initialization" class="level3">
<h3 class="anchored" data-anchor-id="task-specific-scene-loading-and-initialization">Task-Specific scene loading and initialization</h3>
<p>There are 3 specific environments: kitchen, dining room, living room. Objects, robotic arm positions are completely different from each environment. To let users, students could load up the target environment and corresponding objects. We constructed a base environment of ED305 and employed registry-based design, an environment corresponding to a registry. In a registry, we define objects to be loaded, robotic arm positions, Aruco tag positions, world-camera positions, etc. At initialization of specific environment, the script does the following:</p>
<ul>
<li>Loads the base environment.<br>
</li>
<li>Sets the robotic arm, world-camera at specified positions.<br>
</li>
<li>Finally, load all required objects.</li>
</ul>
</section>
<section id="object-reconstructions-in-the-simulation-environment" class="level3">
<h3 class="anchored" data-anchor-id="object-reconstructions-in-the-simulation-environment">Object reconstructions in the simulation environment</h3>
<p>All target objects are identified by Aruco tags which embed the translations and rotations vectors of objects. Such information is later used to initialize simulation assets into the simulation environment.</p>
<p>There is a transformation step before serializing these vectors to files, transforming the translations and rotations from camera-frame to tag-frame as same as the trajectories.<br>
To integrate such business logic into the original UMI pipeline, we only need to implement it as a new service and wire it to the pipeline.</p>
</section>
<section id="replacing-real-world-observations-with-simulation-observations" class="level3">
<h3 class="anchored" data-anchor-id="replacing-real-world-observations-with-simulation-observations">Replacing real-world observations with simulation observations</h3>
<p>To enable policy learning entirely within the simulator while maintaining consistency with real-world trajectories, real-world visual observations captured at each waypoint are replaced with corresponding simulation-rendered RGB images. This observation substitution allows imitation learning to be performed and policy model deployment in simulation.</p>
</section>
<section id="trade-offs-were-made" class="level3">
<h3 class="anchored" data-anchor-id="trade-offs-were-made">Trade-offs were made</h3>
<ul>
<li><strong>Eliminated ROS2</strong>: the ROS2 stacks required complicated multi-container communications which is unnecessary in the scope of this course.<br>
</li>
<li><strong>Replaced real-world collected trajectory with motion-planning:</strong> Due to grasping failure, the synthetic motion planner was employed to generate a completely new trajectory from start to end.</li>
</ul>
</section>
<section id="technical-debts" class="level2">
<h2 class="anchored" data-anchor-id="technical-debts">Technical Debts</h2>
<section id="grasping-workarounds-and-limitations" class="level3">
<h3 class="anchored" data-anchor-id="grasping-workarounds-and-limitations">Grasping Workarounds and Limitations</h3>
<p>The existing implementation contains a temporary grasping workaround that introduces technical debt in the system. Because the robotic arm is unable to consistently achieve a stable physical grasp, the object is artificially constrained to the gripper through a multi-step procedure during motion execution. This mechanism facilitates simulation replay but violates physical realism, causing the approach to fail when applied at policy inference time.</p>
</section>
</section>
<section id="future-works" class="level2">
<h2 class="anchored" data-anchor-id="future-works">Future Works</h2>
<ul>
<li>Resolve the grasping failure<br>
</li>
<li>Build visualization tools around the UMI pipeline for sanity checks purposes, allowing us to eliminate biases from the early stage.</li>
</ul>
</section>
</section>
<section id="appendix" class="level1">
<h1>Appendix:</h1>
<section id="why-not-use-isaaclab" class="level2">
<h2 class="anchored" data-anchor-id="why-not-use-isaaclab">Why not use IsaacLab?</h2>
<p>IsaacLab offers higher-level APIs, workflows, and robotics-oriented abstractions intended to simplify robot configuration, environment definition, and the execution of learning algorithms. In this project, however, these abstractions are unnecessary, as the required functionality is limited to the core simulation environment. Dynamic environment setup is already addressed through base environment initialization and a registry-based design, making the additional IsaacLab abstraction layer redundant for our use case.</p>
</section>
<section id="how-did-the-clunky-arm-movements-issue-get-solved" class="level2">
<h2 class="anchored" data-anchor-id="how-did-the-clunky-arm-movements-issue-get-solved">How did the clunky arm movements issue get solved?</h2>
<p>This issue occurred due to the under-tuned physical properties for the Franka asset, such as damping, stiffness, and target positions of each joint at stand-by mode.</p>
</section>
<section id="docker-based-slam-processing" class="level2">
<h2 class="anchored" data-anchor-id="docker-based-slam-processing">Docker-based SLAM processing</h2>
<p>UMI relies on the ORB-SLAM3 visual SLAM algorithm for trajectory extraction. Since ORB-SLAM3 is a C++ project requiring independent build and compilation steps, a quick and dirty workaround was implemented by containerizing the algorithm and invoking it via subprocess calls from a service layer. This approach complicates debugging and long-term maintenance and is therefore suboptimal for a Python-centric codebase. Future work will focus on integrating ORB-SLAM3 through native bindings.</p>
</section>
<section id="real-world-inference-stack" class="level2">
<h2 class="anchored" data-anchor-id="real-world-inference-stack">Real-world inference stack</h2>
<p>One of the downsides of GoPro devices is not supporting real-time video streaming, a crucial feature to enable policy model deployment in the real-world. The UMI official states that using an external video-stream capture card + GoPro media mods could help solve the issue.</p>
</section>
<section id="ik-solvers-selection" class="level2">
<h2 class="anchored" data-anchor-id="ik-solvers-selection">IK solvers selection</h2>
<p>Many existing Inverse Kinematics (IK) solvers present significant challenges for software deployment, often requiring operating system-level dependencies or being tightly integrated with the ROS ecosystem. This approach is problematic because it leads to bloated Docker containers, complex dependency management, and unpredictable behavior across different operating systems. We ended up using IsaacSim built-in IK solver, ArticulationKinematicsSolver.</p>
<p>We evaluated several IK solvers, with the following results:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>Solver</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>cuRobo</strong></td>
<td>Docker installation proved to be a major hurdle, resulting in an excessively large container.</td>
</tr>
<tr class="even">
<td><strong>Ikpy</strong></td>
<td>Ease of installation due to its management via <code>pip</code>.</td>
</tr>
<tr class="odd">
<td><strong>Moveit2</strong></td>
<td>Its ROS-bound installation created conflicts with our custom-built ROS2 version within IsaacSim, leading to another significant deployment issue.</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="closing-thoughts" class="level1">
<h1>Closing Thoughts</h1>
<p>The goal of replaying trajectories in simulation is to train and evaluate the policy in the simulator by replacing the real-world observations with simulations. The simulation-observations dataset is later used to train the diffusion policy model I may need to take a step back, is replaying trajectories and replacing observations with simulations the only way? What i’m trying to do is to reduce the observations gap between training and inferencing by keeping the observations consistent. If we could ensure the observations consistency between real-world and simulation then the simulator could be used to do 1. synthetic data generation: using motion planning 2. validate, evaluate the trained policy in simulator</p>
</section>
<section id="recorded-demos-gifs" class="level1">
<h1>Recorded Demos (GIFs)</h1>
<p>Human expert demonstration <img src="UMI_kitchen_collect.mp4.gif" class="img-fluid" alt="Human expert demonstration"></p>
<p>First attempt in IsaacSim <img src="UMI_worklog_simulation_first_attempt.mp4.gif" class="img-fluid" alt="First attempt"></p>
<p>Trajectory successfully replayed but failed to grasp <img src="sim_replay.gif" class="img-fluid" alt="Success demo"></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/author31\.github\.io\/my-personal-blog\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>